virtual-keyboard âœ¨ Virtual Gesture Keyboard

A futuristic virtual keyboard powered by hand gestures using MediaPipe, OpenCV, and PyAutoGUI.
Type without touching your keyboard â€” just move your fingers in front of your webcam!

ğŸ“¸ Features (Enhanced Overview)
ğŸ–ï¸ Gesture-Based Typing

Detects fingertips using MediaPipe Hand Tracking

Tracks finger position to determine which key is â€œpressedâ€

Supports both tap and hover based detection

ğŸ¨ Modern & Stylish UI

Neon gradient keyboard

Smooth animations

Transparent keyboard overlay

ğŸ”  Smart Shift Toggle

Easily switch between uppercase and lowercase using gesture flicks

ğŸ“ Live Typing Window

Displays typed text in real-time

Supports multi-line typing

Auto-scroll enabled

ğŸ—‚ï¸ Automatic Saving

Everything typed is saved instantly to typed_output.txt

ğŸ§¾ Instant Notepad Launch

First successful gesture opens Notepad automatically so you can see the text being typed

ğŸ–¼ï¸ Resizable Window

Keyboard window can be resized (not locked to fullscreen)

ğŸ›  Technologies Used
Technology	Purpose
MediaPipe	Hand-tracking, fingertip detection
OpenCV	Camera input, UI rendering
PyAutoGUI	Simulating key presses
Python 3.x	Core application logic
ğŸš€ How to Run
1ï¸âƒ£ Clone the repository
git clone https://github.com/vankam-dinesh/virtual-keyboard.git
cd virtual-keyboard

2ï¸âƒ£ Install dependencies
pip install opencv-python mediapipe pyautogui

3ï¸âƒ£ Run the virtual keyboard
python virtual_keyboard.py

ğŸ—‚ Project Structure
virtual-keyboard/
â”‚
â”œâ”€â”€ images/                  # Screenshots and demo images
â”œâ”€â”€ virtual_keyboard.py      # Main gesture keyboard program
â”œâ”€â”€ main.py                  # Alternate runner (optional)
â”œâ”€â”€ typed_output.txt         # Auto-generated typed text
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ requirements.txt         # Dependencies (optional)

ğŸ“Š System Flowchart
flowchart TD

A[Start Webcam] --> B[MediaPipe Hand Tracking]
B --> C[Identify Fingertip Coordinates]
C --> D[Map Coordinates to Keyboard Buttons]
D --> E{Gesture Detected?}

E -->|Yes| F[Trigger Key Press Event via PyAutoGUI]
E -->|No| C

F --> G[Display Typed Text on UI]
G --> H[Save to typed_output.txt]
H --> I[Open Notepad (first gesture)]
I --> C

ğŸ§  How It Works (Architecture Breakdown)
1ï¸âƒ£ Hand Detection with MediaPipe

Uses built-in hand landmark model

Extracts fingertip positions (index, middle finger)

2ï¸âƒ£ Mapping Finger Positions to Keys

Each keyboard button is a bounding box

If fingertip enters a box â†’ key is â€œpressedâ€

3ï¸âƒ£ Triggering Key Press

PyAutoGUI simulates typing

On first gesture, Notepad auto-opens

Ensures smooth typing experience

4ï¸âƒ£ Rendering the Keyboard

OpenCV draws keys, highlights pressed keys

Creates a neon keyboard UI

5ï¸âƒ£ Real-Time Output

Text instantly appears in the on-screen display

Also saved to typed_output.txt

ğŸ“· Screenshots & Demo

(Add this AFTER uploading your images)

## ğŸ–¼ Demo Screenshot

![Gesture Keyboard](images/your-image.png)

ğŸ§ª Output Examples
âœ” typed_output.txt
Hello, this is a demo of the virtual gesture keyboard!

âœ” Real-time UI

Shows keyboard

Highlights pressed key

Displays typed text

ğŸš€ Future Improvements

âœ‹ Add multi-hand support

ğŸ‘† Add gesture shortcuts (copy, paste, undo)

ğŸ¥ Add on-screen gesture trail

ğŸ”Š Voice feedback for keypress

ğŸ“± Build a GUI-based settings panel

ğŸ™Œ Contributions

Pull requests are welcome!

ğŸ’¬ Support

If you like this project, give it a â­ on GitHub!
