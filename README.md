virtual-keyboard âœ¨ Virtual Gesture Keyboard

A futuristic virtual keyboard powered by hand gestures using MediaPipe, OpenCV, and PyAutoGUI.
Type without touching your keyboard â€” just move your fingers in front of your webcam!

ğŸ“¸ Features (Enhanced Overview)
ğŸ–ï¸ Gesture-Based Typing

Detects fingertips using MediaPipe Hand Tracking

Tracks finger position to determine which key is â€œpressedâ€

Supports both tap and hover based detection

ğŸ¨ Modern & Stylish UI

Neon gradient keyboard

Smooth animations

Transparent keyboard overlay

ğŸ”  Smart Shift Toggle

Easily switch between uppercase and lowercase using gesture flicks

ğŸ“ Live Typing Window

Displays typed text in real-time

Supports multi-line typing

Auto-scroll enabled

ğŸ—‚ï¸ Automatic Saving

Everything typed is saved instantly to typed_output.txt

ğŸ§¾ Instant Notepad Launch

On the first gesture, Notepad opens automatically to show typed text

ğŸ–¼ï¸ Resizable Window

Keyboard window can be resized (not locked to fullscreen)

ğŸ›  Technologies Used
Technology	Purpose
MediaPipe	Hand-tracking, fingertip detection
OpenCV	Camera input, UI rendering
PyAutoGUI	Simulating key presses
Python 3.x	Core application logic
ğŸš€ How to Run
1ï¸âƒ£ Clone the repository
git clone https://github.com/vankam-dinesh/virtual-keyboard.git
cd virtual-keyboard

2ï¸âƒ£ Install dependencies
pip install opencv-python mediapipe pyautogui

3ï¸âƒ£ Run the virtual keyboard
python virtual_keyboard.py

ğŸ—‚ Project Structure
virtual-keyboard/
â”‚
â”œâ”€â”€ images/                  # Screenshots and demo images
â”œâ”€â”€ virtual_keyboard.py      # Main gesture keyboard program
â”œâ”€â”€ main.py                  # Alternate runner (optional)
â”œâ”€â”€ typed_output.txt         # Auto-generated typed text
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ requirements.txt         # Dependencies (optional)

ğŸ“Š System Flowchart
flowchart TD

A[Start Webcam] --> B[MediaPipe Hand Tracking]
B --> C[Identify Fingertip Coordinates]
C --> D[Map Coordinates to Keyboard Buttons]
D --> E{Gesture Detected?}

E -->|Yes| F[Trigger Key Press Event via PyAutoGUI]
E -->|No| C

F --> G[Display Typed Text on UI]
G --> H[Save to typed_output.txt]
H --> I[Open Notepad (first gesture)]
I --> C

ğŸ§  How It Works (Architecture Breakdown)
1ï¸âƒ£ Hand Detection with MediaPipe

Uses built-in hand landmark model

Extracts fingertip positions (index & middle finger)

2ï¸âƒ£ Mapping Finger Positions to Keys

Each keyboard button is a bounding box

If a fingertip enters the box â†’ the key is considered â€œpressedâ€

3ï¸âƒ£ Triggering Key Press

PyAutoGUI simulates the actual typing

Notepad auto-opens on first gesture

4ï¸âƒ£ Rendering the Keyboard

OpenCV draws the keyboard

Highlights the detected key

Neon-style theme for modern look

5ï¸âƒ£ Real-Time Output

Text appears instantly on-screen

Also saved continuously in typed_output.txt

ğŸ“· Screenshots & Demo

(Add this after uploading your image in the /images folder)

## ğŸ–¼ Demo Screenshot
![Gesture Keyboard](images/your-image.png)

ğŸ§ª Output Examples
âœ” Contents of typed_output.txt
Hello, this is a demo of the virtual gesture keyboard!

âœ” Real-time UI shows:

Keyboard layout

Highlighted pressed key

Live typed text preview

ğŸš€ Future Improvements

âœ‹ Add multi-hand support

ğŸ‘† Add gesture shortcuts (copy, paste, undo)

ğŸ¥ Add on-screen gesture trail

ğŸ”Š Voice feedback for keypress

ğŸ“± Build a GUI-based settings panel

ğŸ™Œ Contributions

Pull requests are welcome!
Feel free to fork the project and enhance it.

ğŸ’¬ Support

If you like this project, give it a â­ on GitHub!
